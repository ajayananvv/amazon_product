{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "AqF-8GJHeLT3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "import openpyxl\n",
        "from random import choice\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wb = openpyxl.Workbook()\n",
        "ws=wb.active\n",
        "ws.title=\"Amazon\"\n",
        "ws.append(['URL','NAME OF PRODUCT','PRICE','NO. OF REVIES','RATING'])"
      ],
      "metadata": {
        "id": "y3wGTi1s5Smq"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url=\"https://www.amazon.in/s?k=bags&crid=2M096C61O4MLT&qid=1653308124&sprefix=ba%2Caps%252\"\n",
        "headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36'}\n",
        "page=requests.get(url,headers=headers)\n",
        "page"
      ],
      "metadata": {
        "id": "ajKJc4GH3V87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for j in range(20):\n",
        "  if j==0:\n",
        "    url=\"https://www.amazon.in/s?k=bags&crid=2M096C61O4MLT&qid=1653308124&sprefix=ba%2Caps%252\"\n",
        "  else:\n",
        "    url=f\"https://www.amazon.in/s?k=bags&page={j+1}&crid=2M096C61O4MLT&qid=1697911570&sprefix=ba%2Caps%252&ref=sr_pg_{j+1}\"\n",
        "  headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36'}\n",
        "  page=requests.get(url,headers=headers)\n",
        "  soup = BeautifulSoup(page.content, 'html.parser')\n",
        "  data=soup.find_all('div',class_=\"a-section a-spacing-small a-spacing-top-small\")\n",
        "  l=len(data)\n",
        "  for i in range(l-1):\n",
        "    try:\n",
        "     url=data[i+1].find(\"a\",class_=\"a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal\")\n",
        "     x=url.get(\"href\")\n",
        "     link=\"https://www.amazon.in\" + x\n",
        "     #print(link)\n",
        "\n",
        "     name=data[i+1].find(\"span\",class_=\"a-size-medium a-color-base a-text-normal\").text\n",
        "     #print(name)\n",
        "     price=data[i+1].find_all(\"span\",class_=\"a-offscreen\")[0].text\n",
        "     #print(price)\n",
        "     revies_no=data[i+1].find(\"span\",class_=\"a-size-base s-underline-text\").text\n",
        "     #print(revies_no)\n",
        "     ratt=data[i+1].find(\"span\",class_=\"a-icon-alt\").text\n",
        "     #print(ratt)\n",
        "     ws.append([link,name,price,revies_no,ratt])\n",
        "    except:\n",
        "      pass\n",
        "wb.save('amazon_final.xlsx')\n"
      ],
      "metadata": {
        "id": "WM_v_GWKbRGA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}